<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Remembering and Forgetting in the Digital Era</title>
    <style>
        body {
            font-family: Georgia, serif;
            line-height: 1.7;
            max-width: 900px;
            margin: 40px auto;
            padding: 20px;
        }
        h1, h2, h3 {
            font-family: "Times New Roman", serif;
            margin-top: 40px;
        }
        h1 {
            font-size: 32px;
            text-align: center;
        }
        h2 {
            font-size: 26px;
        }
        h3 {
            font-size: 22px;
        }
        p {
            margin-bottom: 14px;
        }
        .references {
            margin-top: 40px;
        }
    </style>
</head>

<body>

<h1>Remembering and Forgetting in the Digital Era: Human Cognition, Technological Fragility, and Archival Power</h1>

<p>
The rapid development of artificial intelligence and digital technology has fundamentally changed the way human thinking, memory and information interaction. Digital tools have been deeply integrated into daily life, and are gradually shifting the responsibility of cognitive tasks from humans to machines. Tasks that used to rely on memory, problem-solving ability or interpersonal interaction are now often supported or even replaced by digital platforms. These changes have raised a series of urgent issues to be discussed: the future trend of human cognition, the survival of cultural memory, and the construction of the system for managing digital knowledge.
</p>

<p>
At the same time, various infrastructures supporting digital information—from metadata frameworks to algorithm systems—have a profound impact on the classification, acquisition and preservation rules of knowledge. These infrastructures are not neutral. Rather, they reflect specific cultural, political, and institutional values that determine whose voices and histories are represented, and whose are excluded, in the digital record.
</p>

<p>
This paper conducts research on two interrelated core themes: first, how digital technology reshapes human memory, how to generate new risks due to the vulnerability of digital information, and how to challenge the nature of human communication; second, the research focus is shifted to metadata and digital knowledge infrastructure, and explores the rights behind the classification system, the "gatekeeper" mechanism of file management, hidden bias in algorithms, and alternative ethical frameworks such as FAIR and CARE principles.
</p>

<h2>2. Digital Memory and Human Reliance on Technology</h2>

<p>
This part analyzes three interrelated themes: how digital dependence reshapes human memory, the instability of digital information, and the limits of machine interaction. The core point is: while digital technology expands human capabilities, it also forms constraints.
</p>

<h3>2.1 Digital Dependence and the Transformation of Human Memory</h3>

<p>
With the development of AI and digital tools, humans increasingly rely on applications, websites, and search engines as external memory. According to Sparrow, Liu and Wegner (2011), when individuals expect information to be retrievable online, their memory of the information itself weakens while reliance on retrieval paths increases. Thus, human memory strategies shift: we remember how to find information rather than the information itself.
</p>

<p>
Digital tools provide convenience, but cannot replace stable internal memory, which supports autonomous human thinking. Scholars explore whether offloading memory to technology expands or diminishes cognitive capacity (Lodha, 2019). The extended mind hypothesis (Clark & Chalmers, 1998) argues that external tools can become part of cognition, but this also means cognition becomes vulnerable to technological failures, updates, and external conditions.
</p>

<h3>2.2 Fragility of Digital Information</h3>

<p>
Digital information is unstable and depends on hardware, software, formats, and platforms. As technologies evolve, older file formats become unsupported, threatening the preservation of knowledge. Lorie (2001) notes that obsolete machines cannot maintain operation indefinitely, making hardware failure a major threat.
</p>

<p>
The RoweCom/Faxon crisis highlighted how digital resource access can collapse instantly when platforms fail. Portico emerged to provide long-term preservation, later expanding to e-books and digital collections (Wittenberg et al., 2018). Digital media such as CDs, hard drives, and cloud servers all have their limitations, making long-term preservation strategies essential.
</p>

<h3>2.3 Human Communication and the Limits of Machine Interaction</h3>

<p>
Machines cannot replace human communication rooted in social context, emotional nuance, and situational understanding. Suchman (2007) shows that machines follow programmed rules and cannot interpret contextual meaning or silence. Arnd-Caddigan (2015) emphasizes that simulated empathy is not real emotion.
</p>

<p>
As AI becomes more integrated into interaction, it is crucial to recognize the irreplaceable nature of human relationships.
</p>

<h2>3. Metadata, Power, and Digital Knowledge Politics</h2>

<p>
To understand digital cognition, we must analyze the infrastructures that organize knowledge—metadata, classification systems, search algorithms, and archival standards. Metadata frameworks shape what becomes visible or invisible in digital culture.
</p>

<h3>3.1 Metadata Frameworks and the Politics of Classification</h3>

<p>
Classification is political. Bowker & Star (2000) argue all classification systems embed cultural and institutional values. Metadata actively shapes knowledge by determining what is recorded or omitted. Missing dimensions (e.g., race, gender) reproduce systemic inequalities.
</p>

<h3>3.2 Metadata as Gatekeeping</h3>

<p>
Metadata serves as a “gatekeeper,” determining whose stories enter cultural memory (Schwartz & Cook, 2002). Caswell (2014) calls systematic exclusion “symbolic annihilation,” erasing marginalized groups from digital history.
</p>

<h3>3.3 OCR Bias and Algorithm Bias</h3>

<p>
OCR accuracy is lower for non-Latin scripts, handwritten texts, and older fonts, making some cultures digitally invisible. Noble (2018) and Benjamin (2019) show that algorithms reproduce racial and social biases under the guise of neutrality.
</p>

<h2>Conclusion</h2>

<p>
Digital technology reshapes cognition, introduces preservation risks, and embeds power structures in knowledge systems. Human autonomy requires strong internal cognitive abilities, robust preservation strategies, and ethically designed infrastructures. FAIR and CARE principles offer pathways toward inclusive knowledge systems.
</p>

<h2>References</h2>

<div class="references">
<p>Arnd-Caddigan (2015)…</p>
<p>Bowker & Star (2000)…</p>
<p>Caswell (2014)…</p>
<p>Clark & Chalmers (1998)…</p>
<p>Kirchhoff (2008)…</p>
<p>Lodha (2019)…</p>
<p>Lorie (2001)…</p>
<p>Noble (2018)…</p>
<p>Schwartz & Cook (2002)…</p>
<p>Sparrow, Liu, & Wegner (2011)…</p>
<p>Suchman (2007)…</p>
<p>Wittenberg et al. (2018)…</p>
</div>

</body>
</html>
